{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BKK_estimator import Closed_form_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ER_estimator import Closed_form_estimator as Closed_form_estimator0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "def ordered_train_test_split(X, y, n_split = 10, train_size = 0.8, random_state= 0):\n",
    "    # cut observations in 10 deciles (in terms of y values), \n",
    "    # apply train test split on each decile,\n",
    "    # gather back train and test from each decile\n",
    "    ordered = np.argsort(y)\n",
    "    l = int(len(y) / n_split)\n",
    "    indexes = [np.argsort(y)[i*l:(i+1)*l] for i in range(n_split)]\n",
    "    X_known, X_unknown, y_known, y_unknown = zip(*[tts(X[index], y[index], train_size = train_size, random_state = random_state+j) for j, index in enumerate(indexes)])\n",
    "    X_known, X_unknown, y_known, y_unknown = np.concatenate( X_known, axis=0), np.concatenate( X_unknown, axis=0), np.concatenate( y_known, axis=0), np.concatenate( y_unknown, axis=0), \n",
    "    return X_known, X_unknown, y_known, y_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def make_test(X_train, y_train, X_test, y_test, random_state = 0, method = \"BKK\", params = {}):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    if method == \"ER\":\n",
    "        time_start = timer()\n",
    "        cfe = Closed_form_estimator0(eigen_decomposition=True, random_state = random_state, **params) \n",
    "        cfe = cfe.fit(X_train, y_train)\n",
    "        res = cfe.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, cfe.old_loss, cfe.start_iter, np.exp(cfe._params[\"lambda\"].detach().cpu().numpy())\n",
    "    \n",
    "    if method == \"BKK\":\n",
    "        time_start = timer()\n",
    "        cfe = Closed_form_estimator(eigen_decomposition=True, random_state = random_state, **params) \n",
    "        cfe = cfe.fit(X_train, y_train)\n",
    "        res = cfe.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, cfe.old_loss, cfe.start_iter, np.exp(cfe._params[\"lambda\"].detach().cpu().numpy())\n",
    "\n",
    "    if method == \"SBKK\":\n",
    "        time_start = timer()\n",
    "        cfe = Closed_form_estimator(feature_sparsity=True, random_state = random_state, **params) \n",
    "        cfe = cfe.fit(X_train, y_train)\n",
    "        res = cfe.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, cfe.old_loss, cfe.start_iter, np.exp(cfe._params[\"lambda\"].detach().cpu().numpy())\n",
    "\n",
    "    if method == \"ABKK\":\n",
    "        time_start = timer()\n",
    "        cfe = Closed_form_estimator(elastic_feature_sparsity=True, random_state = random_state, **params) \n",
    "        cfe = cfe.fit(X_train, y_train)\n",
    "        res = cfe.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, cfe.old_loss, cfe.start_iter, np.exp(cfe._params[\"lambda\"].detach().cpu().numpy())\n",
    "\n",
    "    if method == \"Ridge\":\n",
    "        time_start = timer()\n",
    "        reg = RidgeCV(cv=5, fit_intercept = False, alphas = np.geomspace(1e-2,1e2,100), **params).fit(X_train, y_train)\n",
    "        res = reg.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, 0, 0, reg.alpha_\n",
    "\n",
    "    if method == \"Lasso\":\n",
    "        time_start = timer()\n",
    "        reg = LassoCV(cv=5, fit_intercept = False, **params).fit(X_train, y_train)\n",
    "        res = reg.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, 0, reg.n_iter_, reg.alpha_\n",
    "\n",
    "    if method == \"Enet\":\n",
    "        time_start = timer()\n",
    "        reg = ElasticNetCV(cv=5, fit_intercept = False, l1_ratio = [.1, .5, .7, .9, .95, .99, 1], **params).fit(X_train, y_train)\n",
    "        res = reg.score(X_test, y_test)\n",
    "        time_stop = timer()\n",
    "        return time_stop - time_start, res, 0, reg.n_iter_, reg.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T experiment Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100\n",
    "n_features = 80\n",
    "methods = [\"ER\",\"BKK\"]\n",
    "scenarii = [\"A\", \"B\", \"C\"]\n",
    "dataset_repository = \"dataset_folder/\"\n",
    "T_values = [0,1,3,10,30,100,300,1000]\n",
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time: \n",
    "    Ts_recorded = np.zeros((len(T_values),len(scenarii), n_simulations, 5))\n",
    "    Ts_processed = np.zeros((len(T_values),len(scenarii), n_simulations))\n",
    "else:\n",
    "    Ts_recorded = np.load(dataset_repository+\"T_impact_synthetic_results.npy\")\n",
    "    Ts_processed = np.load(dataset_repository+\"T_impact_synthetic_processed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "i, method = 0, methods[0]\n",
    "for j, scenario in enumerate(scenarii):\n",
    "    dataset_name = dataset_repository+\"synthetic_data_scenario_\"+scenario+\"_seed_\"\n",
    "    for k, seed in enumerate(range(n_simulations)):\n",
    "        if Ts_processed[i,j,k] == 0.:\n",
    "            try:\n",
    "                print(i,j,k)\n",
    "                X, y = np.load(dataset_name + str(seed)+\"_X.npy\"), np.load(dataset_name + str(seed)+\"_y.npy\")\n",
    "                y = (y - y.mean()) / y.std()\n",
    "                X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 100/1100, random_state= seed*10)\n",
    "                Ts_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method))\n",
    "                np.save(dataset_repository+\"T_impact_synthetic_results\", Ts_recorded)\n",
    "\n",
    "                Ts_processed[i,j,k] = 1.\n",
    "                np.save(dataset_repository+\"T_impact_synthetic_processed\", Ts_processed)\n",
    "            except:\n",
    "                print(\"error\",i,j,k)\n",
    "\n",
    "method = methods[1]\n",
    "for i, T in enumerate(T_values)[1:]:\n",
    "    BKK_params = {\"n_permut\":T}\n",
    "    for j, scenario in enumerate(scenarii):\n",
    "        dataset_name = dataset_repository+\"synthetic_data_scenario_\"+scenario+\"_seed_\"\n",
    "        for k, seed in enumerate(range(n_simulations)):\n",
    "            if Ts_processed[i,j,k] == 0.:\n",
    "                try:\n",
    "                    print(i,j,k)\n",
    "                    X, y = np.load(dataset_name + str(seed)+\"_X.npy\"), np.load(dataset_name + str(seed)+\"_y.npy\")\n",
    "                    y = (y - y.mean()) / y.std()\n",
    "                    X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 100/1100, random_state= seed*10)\n",
    "                    Ts_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method, params = BKK_params))\n",
    "                    np.save(dataset_repository+\"T_impact_synthetic_results\", Ts_recorded)\n",
    "                    \n",
    "                    Ts_processed[i,j,k] = 1.\n",
    "                    np.save(dataset_repository+\"T_impact_synthetic_processed\", Ts_processed)\n",
    "                except:\n",
    "                    print(\"error\",i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T experiment UCI small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100\n",
    "n_features = 80\n",
    "methods = [\"ER\",\"BKK\"]\n",
    "scenarii = [\"0\" + val for val in np.arange(1,9).astype(str)]\n",
    "dataset_repository = \"dataset_folder/\"\n",
    "T_values = [0,1,3,10,30,100,300,1000]\n",
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time: \n",
    "    Tu_recorded = np.zeros((len(T_values),len(scenarii), n_simulations, 5))\n",
    "    Tu_processed = np.zeros((len(T_values),len(scenarii), n_simulations))\n",
    "else:\n",
    "    Tu_recorded = np.load(dataset_repository+\"T_impact_UCI_results.npy\")\n",
    "    Tu_processed = np.load(dataset_repository+\"T_impact_UCI_processed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "i, method = 0, methods[0]\n",
    "for j, scenario in enumerate(scenarii):\n",
    "    dataset_name = dataset_repository+\"UCI_dataset_\"+scenario+\".npy\"\n",
    "    X, y = np.load(dataset_name)[:,:-1],np.load(dataset_name)[:,-1]\n",
    "    y = (y - y.mean()) / y.std()\n",
    "    for k, seed in enumerate(range(n_simulations)):\n",
    "        if Ts_processed[i,j,k] == 0.:\n",
    "            try:\n",
    "                print(i,j,k)\n",
    "                X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 0.8, random_state= seed*10)\n",
    "                Tu_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method))\n",
    "                np.save(dataset_repository+\"T_impact_UCI_results\", Tu_recorded)\n",
    "\n",
    "                Tu_processed[i,j,k] = 1.\n",
    "                np.save(dataset_repository+\"T_impact_UCI_processed\", Tu_processed)\n",
    "            except:\n",
    "                print(\"error\",i,j,k)\n",
    "\n",
    "method = methods[1]\n",
    "for i, T in enumerate(T_values)[1:]:\n",
    "    BKK_params = {\"n_permut\":T}\n",
    "    for j, scenario in enumerate(scenarii):\n",
    "        dataset_name = dataset_repository+\"UCI_dataset_\"+scenario+\".npy\"\n",
    "        X, y = np.load(dataset_name)[:,:-1],np.load(dataset_name)[:,-1]\n",
    "        y = (y - y.mean()) / y.std()\n",
    "        for k, seed in enumerate(range(n_simulations)):\n",
    "            if Tu_processed[i,j,k] == 0.:\n",
    "                try:\n",
    "                    print(i,j,k)\n",
    "                    X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 0.8, random_state= seed*10)\n",
    "                    Tu_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method, params = BKK_params))\n",
    "                    np.save(dataset_repository+\"T_impact_UCI_results\", Tu_recorded)\n",
    "                    \n",
    "                    Tu_processed[i,j,k] = 1.\n",
    "                    np.save(dataset_repository+\"T_impact_UCI_processed\", Tu_processed)\n",
    "                except:\n",
    "                    print(\"error\",i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100\n",
    "n_features = 80\n",
    "methods = [\"BKK\", \"SBKK\", \"ABKK\",\"Ridge\", \"Lasso\", \"Enet\"]\n",
    "scenarii = [\"A\", \"B\", \"C\"]\n",
    "dataset_repository = \"dataset_folder/\"\n",
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time : \n",
    "    fs_processed = np.zeros((len(methods),len(scenarii), n_simulations))\n",
    "    fs_recorded = np.zeros((len(methods),len(scenarii), n_simulations, 5))\n",
    "else: \n",
    "    fs_processed = np.load(dataset_repository+\"fast_synthetic_processed.npy\")\n",
    "    fs_recorded = np.load(dataset_repository+\"fast_synthetic_results.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i, method in enumerate(methods):\n",
    "    for j, scenario in enumerate(scenarii):\n",
    "        dataset_name = dataset_repository+\"synthetic_data_scenario_\"+scenario+\"_seed_\"\n",
    "        for k, seed in enumerate(range(n_simulations)):\n",
    "            if fs_processed[i,j,k] == 0.:\n",
    "                try:\n",
    "                    print(i,j,k)\n",
    "                    X, y = np.load(dataset_name + str(seed)+\"_X.npy\"), np.load(dataset_name + str(seed)+\"_y.npy\")\n",
    "                    y = (y - y.mean()) / y.std()\n",
    "                    X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 100/1100, random_state= seed*10)\n",
    "                    fs_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method))\n",
    "                    np.save(dataset_repository+\"fast_synthetic_results\", fs_recorded)\n",
    "                    \n",
    "                    fs_processed[i,j,k] = 1.\n",
    "                    np.save(dataset_repository+\"fast_synthetic_processed\", fs_processed)\n",
    "                except:\n",
    "                    print(\"error\",i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarii = [500, 1000, 1500, 2000, 2500, 2875]\n",
    "n_simulations = 100\n",
    "methods = [\"BKK\", \"SBKK\", \"ABKK\", \"Ridge\", \"Lasso\", \"Enet\"]\n",
    "dataset_repository = \"dataset_folder/\"\n",
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time:\n",
    "    svm_recorded = np.zeros((len(methods),len(scenarii), n_simulations, 5))\n",
    "    svm_processed = np.zeros((len(methods),len(scenarii), n_simulations))\n",
    "else:\n",
    "    svm_recorded = np.load(dataset_repository+\"fast_svmlib_results.npy\")\n",
    "    svm_processed = np.load(dataset_repository+\"fast_svmlib_proccessed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.load(\"news20__X_train_cut0.8.npy\")\n",
    "X_test = np.load(\"news20__X_test_cut0.8.npy\")\n",
    "y_train = np.load(\"news20_y_train.npy\")\n",
    "y_test = np.load(\"news20_y_test.npy\")\n",
    "m,s = y_train.mean(), y_train.std()\n",
    "y_test = (y_test-m)/s\n",
    "y_train = (y_train-m)/s\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    for j, scenario in enumerate(scenarii):\n",
    "        for k, seed in enumerate(range(n_simulations)):\n",
    "            np.random.seed(k)\n",
    "            sample = np.random.choice(np.arange(X_train.shape[0]), scenario, replace = False)\n",
    "            _X_train, _y_train = X_train[sample], y_train[sample]\n",
    "            _X_test, _y_test = X_test, y_test\n",
    "            if svm_processed[i,j,k] == 0.:\n",
    "                try:\n",
    "                    print(i,j,k)\n",
    "                    svm_recorded[i,j,k] = np.array(make_test(_X_train, _y_train, _X_test, _y_test, random_state = seed, method = method))\n",
    "                    np.save(dataset_repository+\"fast_svmlib_results\", svm_recorded)\n",
    "                    svm_processed[i,j,k] = 1.\n",
    "                    np.save(dataset_repository+\"fast_svmlib_processed\", svm_processed)\n",
    "                except:\n",
    "                    print(\"error\",i,j,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 100\n",
    "methods = [\"BKK\", \"SBKK\", \"ABKK\", \"Ridge\", \"Lasso\", \"Enet\"]\n",
    "scenarii = [\"0\" + val for val in np.arange(1,10).astype(str)]+list(np.arange(10,15).astype(str))\n",
    "dataset_repository = \"dataset_folder/\"\n",
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time:\n",
    "    u_recorded = np.zeros((len(methods),len(scenarii), n_simulations, 5))\n",
    "    u_processed = np.zeros((len(methods),len(scenarii), n_simulations))\n",
    "else:\n",
    "    u_recorded = np.load(dataset_repository+\"fast_UCI_results.npy\")\n",
    "    u_processed = np.load(dataset_repository+\"fast_UCI_proccessed.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for j, scenario in enumerate(scenarii):\n",
    "    dataset_name = dataset_repository+\"UCI_dataset_\"+scenario+\".npy\"\n",
    "    X, y = np.load(dataset_name)[:,:-1],np.load(dataset_name)[:,-1]\n",
    "    y = (y - y.mean()) / y.std()\n",
    "    for i, method in enumerate(methods):\n",
    "        for k, seed in enumerate(range(n_simulations)):\n",
    "            if u_processed[i,j,k] == 0.:\n",
    "                try:\n",
    "                    print(i,j,k)\n",
    "                    X_train, X_test, y_train, y_test = ordered_train_test_split(X, y, n_split = 10, train_size = 0.8, random_state= seed*10)\n",
    "                    u_recorded[i,j,k] = np.array(make_test(X_train, y_train, X_test, y_test, random_state = seed, method = method))\n",
    "                    np.save(dataset_repository+\"fast_UCI_results\", u_recorded)\n",
    "                    u_processed[i,j,k] = 1.\n",
    "                    np.save(dataset_repository+\"fast_UCI_processed\", u_processed)\n",
    "\n",
    "                except:\n",
    "                    print(\"error\",i,j,k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
